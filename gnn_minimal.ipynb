{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN-Only Analysis - No Traditional Baseline Needed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import time\n",
    "import json\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your existing TEC data\n",
    "with pd.HDFStore('./data/gene_network_data.h5') as store:\n",
    "    tec = store['TEC']\n",
    "\n",
    "np_tec_abs = np.abs(tec.to_numpy(copy=True))\n",
    "gene_names = tec.index.tolist()\n",
    "n_genes = len(gene_names)\n",
    "print(f\"Loaded {n_genes} genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNN Model\n",
    "class TEC_GNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_heads=8, dropout=0.3):\n",
    "        super(TEC_GNN, self).__init__()\n",
    "        self.gat1 = GATConv(input_dim, hidden_dim, heads=num_heads, dropout=dropout)\n",
    "        self.gat2 = GATConv(hidden_dim * num_heads, hidden_dim, heads=1, dropout=dropout)\n",
    "        self.dropout = dropout\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.elu(self.gat1(x, edge_index))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        embeddings = self.gat2(x, edge_index)\n",
    "        reconstruction = torch.sigmoid(torch.mm(embeddings, embeddings.t()))\n",
    "        return embeddings, reconstruction\n",
    "\n",
    "print(\"GNN model defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "threshold = 0.75\n",
    "adj_matrix = (np_tec_abs > threshold).astype(float)\n",
    "np.fill_diagonal(adj_matrix, 0)\n",
    "\n",
    "# Edge indices\n",
    "edge_indices = np.where(adj_matrix > 0)\n",
    "edge_index = torch.tensor(np.vstack([edge_indices[0], edge_indices[1]]), dtype=torch.long)\n",
    "\n",
    "# Node features\n",
    "degrees = np.sum(adj_matrix, axis=1)\n",
    "mean_corr = np.mean(np_tec_abs, axis=1)\n",
    "node_features = np.column_stack([degrees, mean_corr])\n",
    "x = torch.tensor(node_features, dtype=torch.float32)\n",
    "target_adj = torch.tensor(adj_matrix, dtype=torch.float32)\n",
    "\n",
    "# Move to device\n",
    "x = x.to(device)\n",
    "edge_index = edge_index.to(device)\n",
    "target_adj = target_adj.to(device)\n",
    "\n",
    "print(f\"Data prepared: {x.shape[0]} nodes, {edge_index.shape[1]} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GNN\n",
    "model = TEC_GNN(input_dim=x.size(1)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.train()\n",
    "start_time = time.time()\n",
    "losses = []\n",
    "\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    embeddings, reconstruction = model(x, edge_index)\n",
    "    loss = F.binary_cross_entropy(reconstruction, target_adj)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss = {loss.item():.6f}\")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "print(f\"Final loss: {losses[-1]:.6f}\")\n",
    "\n",
    "# Get final embeddings\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    final_embeddings, _ = model(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering analysis\n",
    "embeddings_np = final_embeddings.cpu().numpy()\n",
    "\n",
    "# Find optimal clusters\n",
    "silhouette_scores = []\n",
    "for k in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = kmeans.fit_predict(embeddings_np)\n",
    "    score = silhouette_score(embeddings_np, labels)\n",
    "    silhouette_scores.append((k, score))\n",
    "\n",
    "optimal_k, best_score = max(silhouette_scores, key=lambda x: x[1])\n",
    "final_kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "cluster_labels = final_kmeans.fit_predict(embeddings_np)\n",
    "\n",
    "unique_labels, counts = np.unique(cluster_labels, return_counts=True)\n",
    "cluster_sizes = list(zip(unique_labels, counts))\n",
    "cluster_sizes.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"Optimal clusters: {optimal_k}\")\n",
    "print(f\"Silhouette score: {best_score:.4f}\")\n",
    "print(f\"Cluster sizes: {cluster_sizes[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hub analysis\n",
    "influence_scores = np.linalg.norm(embeddings_np, axis=1)\n",
    "hub_indices = np.argsort(influence_scores)[::-1][:50]\n",
    "print(f\"Top 50 hub genes identified by GNN\")\n",
    "print(f\"Hub influence scores range: {influence_scores[hub_indices[0]]:.3f} to {influence_scores[hub_indices[-1]]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity analysis and link prediction\n",
    "similarity_matrix = cosine_similarity(embeddings_np)\n",
    "np.fill_diagonal(similarity_matrix, 0)\n",
    "\n",
    "similarities = similarity_matrix.flatten()\n",
    "similarities = similarities[similarities > 0]\n",
    "\n",
    "# Predict high-confidence links\n",
    "high_sim_indices = np.where(similarity_matrix > 0.8)\n",
    "predictions = []\n",
    "for i, j in zip(high_sim_indices[0], high_sim_indices[1]):\n",
    "    if i < j:\n",
    "        predictions.append((i, j, similarity_matrix[i, j]))\n",
    "\n",
    "predictions.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "print(f\"Mean similarity: {np.mean(similarities):.4f}\")\n",
    "print(f\"High-confidence predictions (>0.8): {len(predictions)}\")\n",
    "print(f\"Top 5 predictions:\")\n",
    "for i, (g1, g2, score) in enumerate(predictions[:5], 1):\n",
    "    print(f\"  {i}. Gene_{g1} - Gene_{g2}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for manuscript\n",
    "results = {\n",
    "    'gnn_results': {\n",
    "        'training_time': training_time,\n",
    "        'final_loss': losses[-1],\n",
    "        'epochs_trained': len(losses),\n",
    "        'optimal_clusters': optimal_k,\n",
    "        'silhouette_score': best_score,\n",
    "        'cluster_sizes': cluster_sizes,\n",
    "        'num_hubs': len(hub_indices),\n",
    "        'mean_similarity': float(np.mean(similarities)),\n",
    "        'high_confidence_predictions': len(predictions),\n",
    "        'top_predictions': predictions[:10]\n",
    "    },\n",
    "    'metadata': {\n",
    "        'total_genes': n_genes,\n",
    "        'threshold': threshold,\n",
    "        'device': str(device)\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('gnn_only_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2, default=str)\n",
    "\n",
    "print(\"\\nGNN ANALYSIS COMPLETE\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Genes analyzed: {n_genes:,}\")\n",
    "print(f\"Training time: {training_time:.1f}s\")\n",
    "print(f\"Clusters found: {optimal_k}\")\n",
    "print(f\"Hub genes: {len(hub_indices)}\")\n",
    "print(f\"Predictions: {len(predictions)}\")\n",
    "print(\"\\nResults saved to gnn_only_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}